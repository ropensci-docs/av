[{"path":"https://docs.ropensci.org/av/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2018 Jeroen Ooms Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://docs.ropensci.org/av/articles/spectrograms.html","id":"spectrogram-video","dir":"Articles","previous_headings":"","what":"Spectrogram video","title":"Spectrograms in R using the 'av' package","text":"can also create spectrogram video like : browser support video tag.","code":"# Create new audio file with first 5 sec av_audio_convert(wonderland, 'short.mp3', total_time = 5) #> [1] \"short.mp3\" av_spectrogram_video('short.mp3', output = 'spectrogram.mp4', width = 1280, height = 720, res = 144)"},{"path":"https://docs.ropensci.org/av/articles/spectrograms.html","id":"compare-with-tunersignal","dir":"Articles","previous_headings":"","what":"Compare with tuneR/signal","title":"Spectrograms in R using the 'av' package","text":"comparison, show thing can achieved tuneR package: use signal package calculate spectrogram similar parameters av:","code":"# Read wav with tuneR data <- tuneR::readMP3('short.mp3')  # demean to remove DC offset snd <- data@left - mean(data@left) # create spectrogram spec <- signal::specgram(x = snd, n = 1024, Fs = data@samp.rate, overlap = 1024 * 0.75)  # normalize and rescale to dB P <- abs(spec$S) P <- P/max(P)  out <- pmax(1e-6, P) dim(out) <- dim(P) out <- log10(out) / log10(1e-6)  # plot spectrogram image(x = spec$t, y = spec$f, z = t(out), ylab = 'Freq [Hz]', xlab = 'Time [s]', useRaster=TRUE)"},{"path":"https://docs.ropensci.org/av/articles/spectrograms.html","id":"compare-with-seewave","dir":"Articles","previous_headings":"","what":"Compare with seewave","title":"Spectrograms in R using the 'av' package","text":"Compare spectrograms using tico audio sample included seewave package:  use av, first save wav file create spectrogram:","code":"library(seewave) library(ggplot2) data(tico) ggspectro(tico, ovlp = 50) + geom_tile(aes(fill = amplitude)) + stat_contour() # First export wav file savewav(tico, filename = 'tico.wav') plot(read_audio_fft('tico.wav'))"},{"path":"https://docs.ropensci.org/av/articles/spectrograms.html","id":"compare-with-phontools","dir":"Articles","previous_headings":"","what":"Compare with phonTools","title":"Spectrograms in R using the 'av' package","text":"Use audio sample included phonTools:  Save wav file create spectrogram. match default window function phonTools:","code":"library(phonTools) #>  #> Attaching package: 'phonTools' #> The following object is masked from 'package:seewave': #>  #>     preemphasis data(sound) spectrogram(sound, maxfreq = sound$fs/2) phonTools::writesound(sound, 'sound.wav') plot(read_audio_fft('sound.wav', window = phonTools::windowfunc(1024, 'kaiser')))"},{"path":"https://docs.ropensci.org/av/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jeroen Ooms. Author, maintainer.","code":""},{"path":"https://docs.ropensci.org/av/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ooms J (2024). av: Working Audio Video R. R package version 0.9.0,  https://docs.ropensci.org/av/, https://ropensci.r-universe.dev/av.","code":"@Manual{,   title = {av: Working with Audio and Video in R},   author = {Jeroen Ooms},   year = {2024},   note = {R package version 0.9.0,  https://docs.ropensci.org/av/},   url = {https://ropensci.r-universe.dev/av}, }"},{"path":"https://docs.ropensci.org/av/index.html","id":"av","dir":"","previous_headings":"","what":"Working with Audio and Video in R","title":"Working with Audio and Video in R","text":"R Bindings FFmpeg","code":""},{"path":"https://docs.ropensci.org/av/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Working with Audio and Video in R","text":"can install av CRAN Debian/Ubuntu first need install libavfilter-dev Fedora / CentOS-9 / RHEL-9 two options. Either install ffmpeg-free-devel (CentOS/RHEL 9, enable EPEL first) Alternatively can also install extensive version ffmpeg-devel rpmfusion. version also available CentOS/RHEL 7 8. See instructions enable rpmfusion via command line.","code":"install.packages(\"av\") sudo apt-get install libavfilter-dev # On CentOS/RHEL 9 first run: yum install -y epel-release yum install ffmpeg-free-devel # Need to enable rpmfusion repository first via link above! sudo yum install ffmpeg-devel"},{"path":"https://docs.ropensci.org/av/index.html","id":"demo-video","dir":"","previous_headings":"","what":"Demo Video","title":"Working with Audio and Video in R","text":"Generate demo video random plots free demo music: demo totally lame, please open PR something better (base R!).","code":"av::av_demo()"},{"path":"https://docs.ropensci.org/av/index.html","id":"using-gganimate","dir":"","previous_headings":"","what":"Using gganimate","title":"Working with Audio and Video in R","text":"can use av_encode_video() renderer gganimate:","code":"# Create the gganimate plot library(gganimate) library(transformr) p <- ggplot(airquality, aes(Day, Temp)) +    geom_line(size = 2, colour = 'steelblue') +    transition_states(Month, 4, 1) +    shadow_mark(size = 1, colour = 'grey')  # Render and show the video q <- 2 df <- animate(p, renderer = av_renderer('animation.mp4'), width = 720*q, height = 480*q, res = 72*q, fps = 25) utils::browseURL('animation.mp4')"},{"path":"https://docs.ropensci.org/av/index.html","id":"video-filters","dir":"","previous_headings":"","what":"Video Filters","title":"Working with Audio and Video in R","text":"can add custom ffmpeg video filter chain. example negate colors, applies orange fade-effect first 15 frames. Filters can also affect final fps video. example filter double fps halves presentation timestamp (pts) frame. Hence output framerate actually 50!","code":"# Continue on the example above filter_render <- av_renderer('orange.mp4', vfilter = 'negate=1, fade=in:0:15:color=orange') df <- animate(p, renderer = filter_render, width = 720*q, height = 480*q, res = 72*q, fps = 25) av::av_media_info('orange.mp4') utils::browseURL('orange.mp4') fast_render <- av_renderer('fast.mp4', vfilter = \"setpts=0.5*PTS\") df <- animate(p, renderer = fast_render, fps = 25) av::av_media_info('fast.mp4') utils::browseURL('fast.mp4')"},{"path":"https://docs.ropensci.org/av/index.html","id":"capture-graphics-without-gganimate","dir":"","previous_headings":"","what":"Capture Graphics (without gganimate)","title":"Working with Audio and Video in R","text":"Instead using gganimate, can use av_capture_graphics() automatically record R graphics turn video. example makes 12 plots adds interpolation filter smoothen transitions frames.","code":"library(gapminder) library(ggplot2) makeplot <- function(){   datalist <- split(gapminder, gapminder$year)   lapply(datalist, function(data){     p <- ggplot(data, aes(gdpPercap, lifeExp, size = pop, color = continent)) +       scale_size(\"population\", limits = range(gapminder$pop)) + geom_point() + ylim(20, 90) +       scale_x_log10(limits = range(gapminder$gdpPercap)) + ggtitle(data$year) + theme_classic()     print(p)   }) }  # Play 1 plot per sec, and use an interpolation filter to convert into 10 fps video_file <- file.path(tempdir(), 'output.mp4') av::av_capture_graphics(makeplot(), video_file, 1280, 720, res = 144, vfilter = 'framerate=fps=10') av::av_media_info(video_file) utils::browseURL(video_file)"},{"path":"https://docs.ropensci.org/av/reference/av_video_images.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert video to images — av_video_images","title":"Convert video to images — av_video_images","text":"Splits video file set image files. Default image format jpeg good speed compression. Use format = \"png\" losless images.","code":""},{"path":"https://docs.ropensci.org/av/reference/av_video_images.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert video to images — av_video_images","text":"","code":"av_video_images(video, destdir = tempfile(), format = \"jpg\", fps = NULL)"},{"path":"https://docs.ropensci.org/av/reference/av_video_images.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert video to images — av_video_images","text":"video input video destdir directory save png files format image format png jpeg, must available av_encoders() fps sample rate images. Use NULL get images.","code":""},{"path":"https://docs.ropensci.org/av/reference/av_video_images.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert video to images — av_video_images","text":"large input videos can set fps sample limited number images per second. also works fractions, example fps = 0.2 output one image every 5 sec video.","code":""},{"path":"https://docs.ropensci.org/av/reference/capturing.html","id":null,"dir":"Reference","previous_headings":"","what":"Record Video from Graphics Device — capturing","title":"Record Video from Graphics Device — capturing","text":"Runs expression captures plots video. av_spectrogram_video function wrapper plots data read_audio_fft moving bar background audio.","code":""},{"path":"https://docs.ropensci.org/av/reference/capturing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Record Video from Graphics Device — capturing","text":"","code":"av_capture_graphics(   expr,   output = \"output.mp4\",   width = 720,   height = 480,   framerate = 1,   vfilter = \"null\",   audio = NULL,   verbose = TRUE,   ... )  av_spectrogram_video(   audio,   output = \"output.mp4\",   framerate = 25,   verbose = TRUE,   ... )"},{"path":"https://docs.ropensci.org/av/reference/capturing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Record Video from Graphics Device — capturing","text":"expr R expression generates graphics capture output name output file. File extension must correspond known container format mp4, mkv, mov, flv. width width pixels graphics device height height pixels graphics device framerate video framerate frames per seconds. input fps, output fps may different specify filter modifies speed interpolates frames. vfilter string defining ffmpeg filter graph. parameter -vf argument ffmpeg command line utility. audio path media file audio stream verbose emit output progress meter counting processed images. Must TRUE FALSE integer valid av_log_level. ... extra graphics parameters passed png()","code":""},{"path":[]},{"path":"https://docs.ropensci.org/av/reference/capturing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Record Video from Graphics Device — capturing","text":"","code":"# \\donttest{ library(gapminder) library(ggplot2) makeplot <- function(){   datalist <- split(gapminder, gapminder$year)   lapply(datalist, function(data){     p <- ggplot(data, aes(gdpPercap, lifeExp, size = pop, color = continent)) +       scale_size(\"population\", limits = range(gapminder$pop)) + geom_point() + ylim(20, 90) +       scale_x_log10(limits = range(gapminder$gdpPercap)) + ggtitle(data$year) + theme_classic()     print(p)   }) }  # Play 1 plot per sec, and use an interpolation filter to convert into 10 fps video_file <- file.path(tempdir(), 'output.mp4') av_capture_graphics(makeplot(), video_file, 1280, 720, res = 144, vfilter = 'framerate=fps=10') #> [1] \"/tmp/Rtmpswmll3/output.mp4\" av::av_media_info(video_file) #> $duration #> [1] 12.9 #>  #> $video #>   width height codec frames framerate  format #> 1  1280    720  h264    130        10 yuv420p #>  #> $audio #> NULL #>  # utils::browseURL(video_file)# }"},{"path":"https://docs.ropensci.org/av/reference/demo.html","id":null,"dir":"Reference","previous_headings":"","what":"Demo Video — demo","title":"Demo Video — demo","text":"Generates random video testing purposes.","code":""},{"path":"https://docs.ropensci.org/av/reference/demo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Demo Video — demo","text":"","code":"av_demo(   output = \"demo.mp4\",   width = 960,   height = 720,   framerate = 5,   verbose = TRUE,   ... )"},{"path":"https://docs.ropensci.org/av/reference/demo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Demo Video — demo","text":"output name output file. File extension must correspond known container format mp4, mkv, mov, flv. width width pixels graphics device height height pixels graphics device framerate video framerate frames per seconds. input fps, output fps may different specify filter modifies speed interpolates frames. verbose emit output progress meter counting processed images. Must TRUE FALSE integer valid av_log_level. ... parameters passed av_capture_graphics.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/av/reference/encoding.html","id":null,"dir":"Reference","previous_headings":"","what":"Encode or Convert Audio / Video — encoding","title":"Encode or Convert Audio / Video — encoding","text":"Encodes set images video, using custom container format, codec, fps, video filters, audio track. input contains video files, effectively combines converts specified output format.","code":""},{"path":"https://docs.ropensci.org/av/reference/encoding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Encode or Convert Audio / Video — encoding","text":"","code":"av_encode_video(   input,   output = \"output.mp4\",   framerate = 24,   vfilter = \"null\",   codec = NULL,   audio = NULL,   verbose = TRUE )  av_video_convert(video, output = \"output.mp4\", verbose = TRUE)  av_audio_convert(   audio,   output = \"output.mp3\",   format = NULL,   channels = NULL,   sample_rate = NULL,   bit_rate = NULL,   start_time = NULL,   total_time = NULL,   verbose = TRUE )"},{"path":"https://docs.ropensci.org/av/reference/encoding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Encode or Convert Audio / Video — encoding","text":"input vector image video files. video input file treated series images. input files width height. output name output file. File extension must correspond known container format mp4, mkv, mov, flv. framerate video framerate frames per seconds. input fps, output fps may different specify filter modifies speed interpolates frames. vfilter string defining ffmpeg filter graph. parameter -vf argument ffmpeg command line utility. codec name video codec listed av_encoders. default libx264 formats, usually best choice. audio audio video input file sound output video verbose emit output progress meter counting processed images. Must TRUE FALSE integer valid av_log_level. video input video file optionally also audio track format valid output format name list av_muxers(). Default NULL infers format file extension. channels number output channels. Default NULL match input. sample_rate output sampling rate. Default NULL match input. bit_rate output bitrate (quality). common value 192000. Default NULL match input. start_time number greater 0, seeks input file position. total_time approximate number seconds limit duration output file.","code":""},{"path":"https://docs.ropensci.org/av/reference/encoding.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Encode or Convert Audio / Video — encoding","text":"target container format audio/video codes automatically determined file extension output file, example mp4, mkv, mov, flv. video output, systems also support gif output, compression~quality gif really bad. gifski package better suited generating animated gif files. Still using proper video format results much better quality. recommended use let ffmpeg choose suitable codec given container format. video formats default libx264 video codec excellent compression works modern browsers, operating systems, digital TVs. convert /raw PCM audio, use file extensions \".ub\" \".sb\" 8bit unsigned signed respectively, \".uw\" \".sw\" 16-bit, see extensions av_muxers(). Alternatively can also convert raw audio PCM setting example format = \"u16le\" (.e. unsigned 16-bit little-endian) another option name column av_muxers(). safe interrupt encoding process pressing CTRL+C, via setTimeLimit. encoding interrupted, output stream properly finalized open files resources properly closed.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/av/reference/formats.html","id":null,"dir":"Reference","previous_headings":"","what":"AV Formats — formats","title":"AV Formats — formats","text":"List supported filters, codecs container formats.","code":""},{"path":"https://docs.ropensci.org/av/reference/formats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AV Formats — formats","text":"","code":"av_encoders()  av_decoders()  av_filters()  av_muxers()  av_demuxers()"},{"path":"https://docs.ropensci.org/av/reference/formats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AV Formats — formats","text":"Encoders decoders convert raw video/audio frames compressed stream data storage transfer. However compressed data stream constitute valid video format yet. Muxers needed interleave one audio/video/subtitle streams, along timestamps, metadata, etc, proper file format, mp4 mkv. Conversely, demuxers needed read file format separate data streams subsequent decoding raw audio/video frames. operating systems natively support demuxing decoding common formats codecs, needed play videos. However encoding muxing videos, ffmpeg must configured specific external libraries given codec format.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/av/reference/info.html","id":null,"dir":"Reference","previous_headings":"","what":"Video Info — info","title":"Video Info — info","text":"Get video info width, height, format, duration framerate. may also used audio input files.","code":""},{"path":"https://docs.ropensci.org/av/reference/info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Video Info — info","text":"","code":"av_media_info(file)"},{"path":"https://docs.ropensci.org/av/reference/info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Video Info — info","text":"file path existing file","code":""},{"path":[]},{"path":"https://docs.ropensci.org/av/reference/logging.html","id":null,"dir":"Reference","previous_headings":"","what":"Logging — logging","title":"Logging — logging","text":"Get set log level.","code":""},{"path":"https://docs.ropensci.org/av/reference/logging.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logging — logging","text":"","code":"av_log_level(set = NULL)"},{"path":"https://docs.ropensci.org/av/reference/logging.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logging — logging","text":"set new log level value","code":""},{"path":[]},{"path":"https://docs.ropensci.org/av/reference/read_audio.html","id":null,"dir":"Reference","previous_headings":"","what":"Read audio binary and frequency data — read_audio_fft","title":"Read audio binary and frequency data — read_audio_fft","text":"Reads raw audio data common audio video format. Use read_audio_bin get raw PCM audio samples, read_audio_fft stream-convert directly frequency domain (spectrum) data using FFmpeg built-FFT.","code":""},{"path":"https://docs.ropensci.org/av/reference/read_audio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read audio binary and frequency data — read_audio_fft","text":"","code":"read_audio_fft(   audio,   window = hanning(1024),   overlap = 0.75,   sample_rate = NULL,   start_time = NULL,   end_time = NULL )  read_audio_bin(   audio,   channels = NULL,   sample_rate = NULL,   start_time = NULL,   end_time = NULL )  write_audio_bin(   pcm_data,   pcm_channels = 1L,   pcm_format = \"s32le\",   output = \"output.mp3\",   ... )"},{"path":"https://docs.ropensci.org/av/reference/read_audio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read audio binary and frequency data — read_audio_fft","text":"audio path input sound video file containing audio stream window vector weights defining moving fft window function. length vector size window hence determines output frequency range. overlap value 0 1 overlap proportion moving fft windows sample_rate downsample audio reduce FFT output size. Default keeps sample rate input file. start_time, end_time position (seconds) cut input stream processed. channels number output channels, set 1 convert mono sound pcm_data integer vector returned read_audio_bin pcm_channels number channels data. Use value entered read_audio_bin. pcm_format always s32le (signed 32-bit integer) now output passed av_audio_convert ... paramters av_audio_convert","code":""},{"path":"https://docs.ropensci.org/av/reference/read_audio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read audio binary and frequency data — read_audio_fft","text":"Currently read_audio_fft automatically converts input audio mono channel get single matrix. Use plot() method data returned read_audio_fft show spectrogram. av_spectrogram_video generates video plays audio showing animated spectrogram moving status bar, cool.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/av/reference/read_audio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read audio binary and frequency data — read_audio_fft","text":"","code":"# Use a 5 sec fragment wonderland <- system.file('samples/Synapsis-Wonderland.mp3', package='av')  # Read initial 5 sec as as frequency spectrum fft_data <- read_audio_fft(wonderland, end_time = 5.0) dim(fft_data) #> [1] 512 860  # Plot the spectrogram plot(fft_data)   # Show other parameters dim(read_audio_fft(wonderland, end_time = 5.0, hamming(2048))) #> [1] 1024  430 dim(read_audio_fft(wonderland, end_time = 5.0, hamming(4096))) #> [1] 2048  215"},{"path":"https://docs.ropensci.org/av/reference/winfunc.html","id":null,"dir":"Reference","previous_headings":"","what":"Window functions — window functions","title":"Window functions — window functions","text":"Several common windows function generators. functions return vector weights use read_audio_fft.","code":""},{"path":"https://docs.ropensci.org/av/reference/winfunc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Window functions — window functions","text":"","code":"hanning(n)  hamming(n)  blackman(n)  bartlett(n)  welch(n)  flattop(n)  bharris(n)  bnuttall(n)  sine(n)  nuttall(n)  bhann(n)  lanczos(n)  gauss(n)  tukey(n)  dolph(n)  cauchy(n)  parzen(n)  bohman(n)"},{"path":"https://docs.ropensci.org/av/reference/winfunc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Window functions — window functions","text":"n size window (number weights generate)","code":""},{"path":"https://docs.ropensci.org/av/reference/winfunc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Window functions — window functions","text":"","code":"# Window functions plot(hanning(1024), type = 'l', xlab = 'window', ylab = 'weight') lines(hamming(1024), type = 'l', col = 'red') lines(bartlett(1024), type = 'l', col = 'blue') lines(welch(1024), type = 'l', col = 'purple') lines(flattop(1024), type = 'l', col = 'darkgreen')"}]
